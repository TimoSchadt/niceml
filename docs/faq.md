# Frequently asked Questions

## How can I add a run configuration to PyCharm?

If you want to use your own pipeline configuration or are tired to type
the make commands into the terminal, PyCharm offers you to use run
configurations.

In PyCharm, search for the run configuration editor. Usually it can be
found in the upper right corner of PyCharm. Otherwise, search the
[official PyCharm documentation](https://www.jetbrains.com/help/pycharm/run-debug-configuration.html)
to find it.

Add a new configuration using the Python template. Switch the 'target'
from 'script path' to 'module name', and set it to use 'dagster'. The
'Parameters' are what you would type in the terminal after the module
name. In case of a training, you can adjust the following code to your
needs and add it to the configuration:

``` ssh
job execute -m niceml.dagster.jobs.repository -j job_train -c configs/jobs/<path to your job yaml>
```

If needed, you can make the '.env' file available for your trainings
run. Just add your .env-file and check 'Enable EnvFile' in the 'EnvFile'
tab of the run configuration.

Save everything, and you are ready to run and debug your experiment.

> **Tipp:** You can also add a run configuration for the dashboard.
> Just set the module name to `streamlit` and the parameters to `run
> niceml/dashboard/dashboard.py configs/dashboard/<path to your
> dashboard yaml>`

## What is the setup of the trainings pipeline?

The training process consists of three steps: training, prediction, and
analysis. Each step serves a specific purpose in the training pipeline:

1. **Training**: During this step, the model learns from the training 
data to improve its performance. The model parameters are updated
iteratively based on the calculated loss and optimization algorithm.

2. **Prediction**: After training, the trained model is used to make
predictions on unseen data. This step allows you to evaluate the
model's performance on new images and assess its ability to identify
objects accurately.

3. **Analysis**: Once the prediction step is complete, niceML performs
an analysis of the trained model. This may include computing additional
metrics, or providing insights into the model's behavior and
performance, as well as checking if the training process was successful.

## Which information does niceML show, when a training is run?

During the training process, niceML provides real-time updates on the
progress:

- First, niceML will give an overview about the **layers of the model**
being trained. This allows you to inspect the architecture and
understand the composition of the model.
- A progress bar indicates the **number of images that have
already been processed** by the training.
- The **loss and other metrics** are being calculated and displayed
during the training. This allows you to monitor the performance of the
model.

## Can I use PyTorch with niceML?

Currently, no. But we want to implement it in future versions of
niceML.

## How does the Test Data generated by niceML look like?

The `niceml generate` command allows you to create sample images with
numbers randomly placed on them. The numbers represent the objects or
regions, the model should be able to identify.

The following five types of files are generated:

- **Test Images**: The test images are created based on thumbnail images
provided by niceML, which are augmented in varying degree. The numbers
are randomly chosen, colored and placed on them. These images serve as
the foundation for training and evaluating your model.

- **Mask Images**: For each test image, a corresponding mask image is
generated. The mask image has the same dimensions as the reference
image, with the numbers represented in black and the remaining regions
in white. These masks help the model to locate the regions which it
should learn to identify.

- **Label Information**: For each test image, label information in the
form of a JSON file is generated. This file contains the location
coordinates of the numbers on each test image. The label information
serves as ground-truth data for the model to learn and evaluate its
performance.

- **Number Images**: Additionally, niceML generates cropped versions of
the test images, focusing only on the regions where the numbers are
present. These number images provide isolated representations of the
individual objects or regions that the model should be able to identify.

- **Tabular**: niceML converts the number images into a dataframe
format. Each row in the dataframe represents the information of one
number image. The number shown in the image can be read from the 'label'
column. The images are converted from RGB to grayscale and scaled
to a fixed size, the default is 10x10 pixels. If the original image is
not square, black borders are added to fill the missing space. The
dataframe represents the color of each pixel in the 10x10 image, with
each column corresponding to one pixel. This dataframe can be useful
for testing simple classification tasks with tabular data.

Test image and its mask image:

![Augmented test image](test-data-sample1.png#only-light){: width="300px" : style="border: 1px solid #DCDCDC;" }
![Augmented test image](test-data-sample1_mask.png#only-light){: width="300px" : style="border: 1px solid #DCDCDC;" }
![Augmented test image](test-data-sample1.png#only-dark){: width="300px"}
![Augmented test image](test-data-sample1_mask.png#only-dark){: width="300px"}

??? example "Generated label data"
    ``` json title="augmented.json"
    --8<-- "docs/test-data-sample1.json"
    ```
Number image example:

![Thumbnail test image](test-data-sample_cropped.png#only-light){: width="150px" : style="border: 1px solid #D3D3D3;"}
![Thumbnail test image](test-data-sample_cropped.png#only-dark){: width="150px"}

??? example "Tabular data"
    {{ read_csv('docs/dataframe.csv') }}


!!! info "Data split and cropping"
    After generating the test data using niceML, the resulting folder
    structure will have the following subfolders:

    - **number_data**: This folder contains the generated images,
        their corresponding labels, and masks.
    - **number_data_split**: In this folder, the generated data is
        split into three subfolders: `train`, `test`, and `validation`.
        Each subfolder contains the images, labels, and masks
        corresponding to the respective dataset split. The image files
        are sorted together with their corresponding label and mask
        files.
    - **numbers_cropped_split**: This folder contains cropped
        versions of the generated images, focusing only on the regions
        where the numbers are present. Each cropped number image is
        named after the test image it originated from and is placed in
        the same split folder as the original image (`train`, `test`, or
        `validation`). This allows for convenient access to the isolated
        number images for further analysis or processing.
    - **numbers_tabular_data**: This folder contains the tabular data
        of the cropped images. Each split folder contains a separate
        dataframe with only the information of images of that split.
